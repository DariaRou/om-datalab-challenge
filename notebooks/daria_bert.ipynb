{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"colab":{"name":"Bert.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"d48cbda1-d40c-4569-9a9e-9c5a0a441e62","executionInfo":{"status":"ok","timestamp":1623388996563,"user_tz":-120,"elapsed":265,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.datasets import imdb\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers.convolutional import Convolution1D\n","from keras.layers.convolutional import MaxPooling1D\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing import sequence"],"id":"d48cbda1-d40c-4569-9a9e-9c5a0a441e62","execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53Edfe-6Y35L","executionInfo":{"status":"ok","timestamp":1623389002193,"user_tz":-120,"elapsed":4821,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}},"outputId":"94d5c55a-ae84-4c14-93bc-a06e0b22b209"},"source":["!pip install transformers==2.8.0 \n","!pip install pytorch_lightning==0.7.5"],"id":"53Edfe-6Y35L","execution_count":19,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n","Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.5.2)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.17.92)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.1.95)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (0.0.45)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.10.0)\n","Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (0.4.2)\n","Requirement already satisfied: botocore<1.21.0,>=1.20.92 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0) (1.20.92)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.92->boto3->transformers==2.8.0) (2.8.1)\n","Requirement already satisfied: pytorch_lightning==0.7.5 in /usr/local/lib/python3.7/dist-packages (0.7.5)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==0.7.5) (4.41.1)\n","Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==0.7.5) (1.19.5)\n","Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==0.7.5) (2.5.0)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==0.7.5) (0.18.2)\n","Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==0.7.5) (1.8.1+cu101)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.12.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (57.0.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (2.23.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.36.2)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.34.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.30.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->pytorch_lightning==0.7.5) (3.7.4.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.15.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (2020.12.5)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.7.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.4.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"895ce934-dab7-4b4e-a140-8f664db32e6a","executionInfo":{"status":"ok","timestamp":1623389002193,"user_tz":-120,"elapsed":8,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}}},"source":["import pandas as pd\n","import torch\n","from tqdm import tqdm, trange\n","import numpy as np\n","\n","\n","# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.sequence import pad_sequences\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import CamembertTokenizer, CamembertForSequenceClassification\n","from transformers import AdamW"],"id":"895ce934-dab7-4b4e-a140-8f664db32e6a","execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"6d9c33aa-c69d-4dcc-94f9-e938e7e65ccb","executionInfo":{"status":"ok","timestamp":1623389981056,"user_tz":-120,"elapsed":311,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}}},"source":["epochs = 5\n","MAX_LEN = 128\n","batch_size = 16\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"id":"6d9c33aa-c69d-4dcc-94f9-e938e7e65ccb","execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"70e2e0a1-6db3-4486-9b1c-3e51aa904f46","executionInfo":{"status":"ok","timestamp":1623389002194,"user_tz":-120,"elapsed":8,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}}},"source":[""],"id":"70e2e0a1-6db3-4486-9b1c-3e51aa904f46","execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_8hORecnaOAd","executionInfo":{"status":"ok","timestamp":1623389002194,"user_tz":-120,"elapsed":8,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}},"outputId":"4d84e29c-2572-43a7-c77b-df6546d859a0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"_8hORecnaOAd","execution_count":22,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6eae3f4a-c522-44de-b919-cc2a515bd5e9","executionInfo":{"status":"ok","timestamp":1623389002194,"user_tz":-120,"elapsed":7,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}}},"source":["data_path = '/content/drive/MyDrive/Colab Notebooks/data/'"],"id":"6eae3f4a-c522-44de-b919-cc2a515bd5e9","execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"586caf63-dcc6-48fd-b463-f785dd658cbd","executionInfo":{"status":"ok","timestamp":1623389004766,"user_tz":-120,"elapsed":2579,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}},"outputId":"c90ea315-4b4f-4bfa-903e-ef28970842c4"},"source":["df = pd.read_csv(data_path + 'french_tweets.csv').sample(10000).reset_index(drop=True)\n","df.head()"],"id":"586caf63-dcc6-48fd-b463-f785dd658cbd","execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Hmv uk ne l'a pas disponible pour pré-commande...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>Encore malade afta 3 jours !!!!!! Mauvais timb...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>Non, je plaisante! Je suis vraiment désolé ......</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>Faire du shopping avec la grand-mère</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>Je continue de manquer le spectacle cette sais...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label                                               text\n","0      0  Hmv uk ne l'a pas disponible pour pré-commande...\n","1      0  Encore malade afta 3 jours !!!!!! Mauvais timb...\n","2      0  Non, je plaisante! Je suis vraiment désolé ......\n","3      1               Faire du shopping avec la grand-mère\n","4      1  Je continue de manquer le spectacle cette sais..."]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uJisAyA5hjzI","executionInfo":{"status":"ok","timestamp":1623389004767,"user_tz":-120,"elapsed":19,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}},"outputId":"5ab091a6-4aac-408c-c919-44e729750881"},"source":["df.shape"],"id":"uJisAyA5hjzI","execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 2)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"38fcbfc7-b0c6-4dc5-97e0-db7eb6dcda1f","executionInfo":{"status":"ok","timestamp":1623389004767,"user_tz":-120,"elapsed":10,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}}},"source":["tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)"],"id":"38fcbfc7-b0c6-4dc5-97e0-db7eb6dcda1f","execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"f59e6e7e-8df4-4a9c-9096-f6b345ef5694","executionInfo":{"status":"ok","timestamp":1623389004767,"user_tz":-120,"elapsed":10,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}}},"source":["from transformers import CamembertTokenizer\n","\n","model_name = \"camembert-base\"\n","tokenizer = CamembertTokenizer.from_pretrained(model_name)"],"id":"f59e6e7e-8df4-4a9c-9096-f6b345ef5694","execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"602c659e-0747-47d9-938e-464059db80f7","executionInfo":{"status":"ok","timestamp":1623389006739,"user_tz":-120,"elapsed":1981,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}}},"source":["# Creates list of texts and labels\n","text = df['text'].to_list()\n","labels = df['label'].to_list()\n","\n","#user tokenizer to convert sentences into tokenizer\n","input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN) for sent in text]\n","\n","# Pad our input tokens\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","# Create attention masks\n","attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]  \n","    attention_masks.append(seq_mask)"],"id":"602c659e-0747-47d9-938e-464059db80f7","execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"80540fb0-81b1-414b-8aee-c32505addaa7","executionInfo":{"status":"ok","timestamp":1623389006740,"user_tz":-120,"elapsed":7,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}}},"source":["# Use train_test_split to split our data into train and validation sets for training\n","train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n","                                                            random_state=42, test_size=0.1)\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"id":"80540fb0-81b1-414b-8aee-c32505addaa7","execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecBL0aZBfMaB","executionInfo":{"status":"ok","timestamp":1623389011125,"user_tz":-120,"elapsed":4391,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}},"outputId":"cfe1fd05-3abe-4210-eca1-aaf8a9c476fa"},"source":["model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=2)\n","model.to(device)"],"id":"ecBL0aZBfMaB","execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CamembertForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"_sR6ngN2fQPF","executionInfo":{"status":"ok","timestamp":1623389011126,"user_tz":-120,"elapsed":16,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}}},"source":["param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=10e-8)\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"id":"_sR6ngN2fQPF","execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2SF0QNlDfV5X","executionInfo":{"status":"ok","timestamp":1623391027122,"user_tz":-120,"elapsed":1038907,"user":{"displayName":"Daria Goriachun","photoUrl":"","userId":"05427975547422938293"}},"outputId":"a42ded56-74ca-42ec-f709-48769d41f9f8"},"source":["# Store our loss and accuracy for plotting if we want to visualize training evolution per epochs after the training process\n","train_loss_set = []\n","\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):  \n","    # Tracking variables for training\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","  \n","    # Train the model\n","    model.train()\n","    for step, batch in enumerate(train_dataloader):\n","        # Add batch to device CPU or GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Clear out the gradients (by default they accumulate)\n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","        # Get loss value\n","        loss = outputs[0]\n","        # Add it to train loss list\n","        train_loss_set.append(loss.item())    \n","        # Backward pass\n","        loss.backward()\n","        # Update parameters and take a step using the computed gradient\n","        optimizer.step()\n","    \n","        # Update tracking variables\n","        tr_loss += loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","\n","    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","    \n","    \n","\n","\n","    # Tracking variables for validation\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    # Validation of the model\n","    model.eval()\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        # Add batch to device CPU or GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions\n","            outputs =  model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","            loss, logits = outputs[:2]\n","    \n","        # Move logits and labels to CPU if GPU is used\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    \n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"],"id":"2SF0QNlDfV5X","execution_count":34,"outputs":[{"output_type":"stream","text":["\n","Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.1619363009241504\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  20%|██        | 1/5 [03:28<13:55, 208.75s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.8045634920634921\n","Train loss: 0.11688997238034095\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  40%|████      | 2/5 [06:56<10:25, 208.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.7936507936507936\n","Train loss: 0.07965581123981803\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  60%|██████    | 3/5 [10:23<06:56, 208.11s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.7956349206349206\n","Train loss: 0.06266275354409608\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  80%|████████  | 4/5 [13:51<03:27, 207.86s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.7886904761904762\n","Train loss: 0.05291955858149746\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 5/5 [17:18<00:00, 207.70s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.7857142857142857\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Fw3pHSqcp2PZ"},"source":[""],"id":"Fw3pHSqcp2PZ","execution_count":null,"outputs":[]}]}